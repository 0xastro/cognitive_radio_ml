{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.5.3 (default, May 10 2017, 15:05:55) \n",
      "[GCC 6.3.1 20161221 (Red Hat 6.3.1-1)]\n",
      "Pandas Version: 0.20.1\n",
      "matplotlib Version: 2.0.2\n",
      "NumPy Version: 1.12.1\n",
      "SciPy Version: 0.19.0\n",
      "IPython Version: 6.0.0\n",
      "Scikit-learn Version: 0.18.1\n",
      "graphviz Version: 0.7.1\n",
      "Mglearn Version: 0.1.5\n"
     ]
    }
   ],
   "source": [
    "# Required modules\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import sklearn\n",
    "import graphviz\n",
    "import mglearn\n",
    "import sys\n",
    "\n",
    "print(\"Python Version: {}\".format(sys.version))\n",
    "print(\"Pandas Version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib Version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy Version: {}\".format(np.__version__))\n",
    "print(\"SciPy Version: {}\".format(sp.__version__))\n",
    "print(\"IPython Version: {}\".format(IPython.__version__))\n",
    "print(\"Scikit-learn Version: {}\".format(sklearn.__version__))\n",
    "print(\"graphviz Version: {}\".format(graphviz.__version__))\n",
    "print(\"Mglearn Version: {}\".format(mglearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constant parameters given by the DySpan PU setup                              \n",
    "DELAY_1 = 0.005 # tau1                                                          \n",
    "DELAY_2 = 0.01  # tau2                                                          \n",
    "TCONST = 0.002                                                                  \n",
    "MEAN1 = 0.02    # lambda1                                                       \n",
    "MEAN2 = 0.01    # lambda2                                                       \n",
    "MEAN3 = 0.005   # lambda3 \n",
    "N_CHAN = 4      # Number of channels\n",
    "N_SCN = 10      # Number of scenarios\n",
    "N_SAMPS = 4000  # Number of samples in the dataset per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create iterables for packet rate and variance\n",
    "if_time_scn_ch = [[[channel] for channel in range(N_CHAN)] \n",
    "                  for scenario in range(N_SCN)]\n",
    "packet_rate_scn = [[] for scenario in range(N_SCN)]\n",
    "variance_scn = [[] for scenario in range(N_SCN)]\n",
    "\n",
    "for scenario in range(N_SCN):\n",
    "    for channel in range(N_CHAN):\n",
    "        if_time_scn_ch[scenario][channel] = sp.fromfile(open(\n",
    "            \"../../data/feature_extraction/2/interframe_time_ch_{}_scn_{}.dat\"\n",
    "            .format(channel+1, scenario)), dtype=sp.float32)\n",
    "    packet_rate_scn[scenario] = sp.fromfile(open(\"../../data/feature_extraction/2/packet_rate_scn_{}.dat\".format(scenario)),\n",
    "                                                dtype=sp.float32)\n",
    "    variance_scn[scenario] = sp.fromfile(open(\"../../data/feature_extraction/2/variance_scn_{}.dat\".format(scenario)),\n",
    "                                             dtype=sp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a vector that includes the interframe time for all channels\n",
    "if_vector = [[] for i in range(N_SAMPS*N_SCN)]\n",
    "for scn in range(N_SCN):\n",
    "    for i in range(N_SAMPS):\n",
    "        for chan in range(N_CHAN):\n",
    "            if_vector[i + N_SAMPS*scn].append(if_time_scn_ch[scn][chan][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate label vector\n",
    "labels = [i for i in range(N_SCN) for n in range(N_SAMPS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/17485747/how-to-convert-a-nested-list-into-a-one-dimensional-list-in-python\n",
    "from collections import Iterable\n",
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data list that includes all data in a list per frames\n",
    "data_nested = []\n",
    "# first generate a long list that includes the packet_rates one scenario\n",
    "# after the other, and the same for the variances\n",
    "# packet_rate = [scn0, scn1, ..., scn9]\n",
    "# len(packet_rate) = N_SAMPS * N_SCN\n",
    "packet_rate = []\n",
    "variance = []\n",
    "for scn in range(N_SCN):\n",
    "    for i in range(N_SAMPS):\n",
    "            packet_rate.append(packet_rate_scn[scn][i])\n",
    "            variance.append(variance_scn[scn][i])\n",
    "\n",
    "data_nested = list(zip(if_vector, packet_rate, variance))\n",
    "# Until this point 'data' is a nested list. It needs to be flattened \n",
    "# to use it with sci-kit\n",
    "# TODO: just don't generate it nested and save this method...\n",
    "data = [[] for i in range(len(data_nested))]\n",
    "for i in range(len(data_nested)):\n",
    "    data[i] = list(flatten(data_nested[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now the data is ready to start applying sci-kit algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We start with the KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Generate the model\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "# Make predictions based on the test data\n",
    "prediction = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9982\n"
     ]
    }
   ],
   "source": [
    "# Check the model accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99819999999999998, 0.99819999999999998, 0.99809999999999999, 0.99660000000000004]\n"
     ]
    }
   ],
   "source": [
    "# testing training in a loop\n",
    "knn_list = []\n",
    "predictions = []\n",
    "accs = []\n",
    "n_neighbors = [2, 4, 10, 50]\n",
    "for n in range(len(n_neighbors)):\n",
    "    knn_list.append(KNeighborsClassifier(n_neighbors=n_neighbors[n]))\n",
    "    knn_list[n].fit(X_train, y_train)\n",
    "    predictions.append(knn_list[n].predict(X_test))\n",
    "    accs.append(accuracy_score(y_test, predictions[n]))\n",
    "\n",
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "100\n",
      "1000\n",
      "10000\n",
      "100000\n",
      "[0.99050000000000005, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003]\n",
      "[13.882, 14.815, 14.219, 14.727, 13.764, 14.338]\n",
      "[1.559, 1.497, 1.48, 1.506, 1.536, 1.562]\n"
     ]
    }
   ],
   "source": [
    "# Training in a loop using SVM\n",
    "# http://scikit-learn.org/stable/modules/svm.html\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "svc_list = []\n",
    "svc_pred = []\n",
    "svc_accs = []\n",
    "svc_fit_times = []\n",
    "svc_pred_times = []\n",
    "svc_complexities = [1, 10, 100, 1000, 10000, 100000]\n",
    "\n",
    "for n in range(len(svc_complexities)):\n",
    "    svc_list.append(SVC(kernel='rbf', C=float(svc_complexities[n])))\n",
    "    t0 = time()\n",
    "    svc_list[n].fit(X_train, y_train)\n",
    "    svc_fit_times.append(round(time() - t0, 3))\n",
    "    t0 = time()\n",
    "    svc_pred.append(svc_list[n].predict(X_test))\n",
    "    svc_pred_times.append(round(time() - t0, 3))\n",
    "    svc_accs.append(accuracy_score(y_test, svc_pred[n]))\n",
    "    \n",
    "print(svc_accs)\n",
    "print(svc_fit_times)\n",
    "print(svc_pred_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
