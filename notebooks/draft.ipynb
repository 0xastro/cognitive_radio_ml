{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.2 | packaged by conda-forge | (default, Jul 23 2017, 22:59:30) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Pandas Version: 0.20.3\n",
      "matplotlib Version: 2.0.2\n",
      "NumPy Version: 1.13.1\n",
      "SciPy Version: 0.19.1\n",
      "IPython Version: 6.1.0\n",
      "Scikit-learn Version: 0.18.2\n",
      "graphviz Version: 0.5.2\n"
     ]
    }
   ],
   "source": [
    "# Required modules\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import sklearn\n",
    "import graphviz\n",
    "# import mglearn\n",
    "import sys\n",
    "\n",
    "print(\"Python Version: {}\".format(sys.version))\n",
    "print(\"Pandas Version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib Version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy Version: {}\".format(np.__version__))\n",
    "print(\"SciPy Version: {}\".format(sp.__version__))\n",
    "print(\"IPython Version: {}\".format(IPython.__version__))\n",
    "print(\"Scikit-learn Version: {}\".format(sklearn.__version__))\n",
    "print(\"graphviz Version: {}\".format(graphviz.__version__))\n",
    "# print(\"Mglearn Version: {}\".format(mglearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constant parameters given by the DySpan PU setup                              \n",
    "DELAY_1 = 0.005 # tau1                                                          \n",
    "DELAY_2 = 0.01  # tau2                                                          \n",
    "TCONST = 0.002                                                                  \n",
    "MEAN1 = 0.02    # lambda1                                                       \n",
    "MEAN2 = 0.01    # lambda2                                                       \n",
    "MEAN3 = 0.005   # lambda3 \n",
    "N_CHAN = 4      # Number of channels\n",
    "N_SCN = 10      # Number of scenarios\n",
    "N_SAMPS = 4000  # Number of samples in the dataset per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9ffd7768a8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscenario\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_SCN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_CHAN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         if_time_scn_ch[scenario][channel] = sp.fromfile(open(\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;34m\"../../data/feature_extraction/2/interframe_time_ch_{}_scn_{}.dat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             .format(channel+1, scenario)), dtype=sp.float32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "# Or avoid doing that per hand and create a list with the following format:\n",
    "# if_time_scn_[]_ch_[]\n",
    "# [[scenario 0, channel 1], [scenario 0, channel 2], ..., [scenario 0, channel 4]],\n",
    "# [[scenario 1, channel 1], [scenario 1, channel 2], ..., [scenario 1, channel 4]],\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# [[scenario 9, channel 1], [scenario 9, channel 2], ..., [scenario 9, channel 4]],\n",
    "\n",
    "# BETTER TO START THINKING IN CHANNEL 0 TO 3\n",
    "\n",
    "if_time_scn_ch = [[[channel] for channel in range(N_CHAN)] \n",
    "                  for scenario in range(N_SCN)]\n",
    "\n",
    "for scenario in range(N_SCN):\n",
    "    for channel in range(N_CHAN):\n",
    "        if_time_scn_ch[scenario][channel] = sp.fromfile(open(\n",
    "            \"../../data/feature_extraction/2/interframe_time_ch_{}_scn_{}.dat\"\n",
    "            .format(channel+1, scenario)), dtype=sp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the same automation for the interframe_delays in a list\n",
    "interframe_delays_scn = [[] for i in range(N_SCN)]\n",
    "for scenario in range(N_SCN):\n",
    "    interframe_delays_scn[scenario] = np.transpose(np.array([if_time_scn_ch[scenario][channel] for channel in range(N_CHAN)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create iterables for packet rate and variance\n",
    "packet_rate_scn = [[] for scenario in range(N_SCN)]\n",
    "variance_scn = [[] for scenario in range(N_SCN)]\n",
    "\n",
    "for scenario in range(N_SCN):\n",
    "    packet_rate_scn[scenario] = sp.fromfile(open(\"../../data/feature_extraction/2/packet_rate_scn_{}.dat\".format(scenario)),\n",
    "                                                dtype=sp.float32)\n",
    "    variance_scn[scenario] = sp.fromfile(open(\"../../data/feature_extraction/2/variance_scn_{}.dat\".format(scenario)),\n",
    "                                             dtype=sp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Interframe delays for scenario 0: 4500\n",
      "Shape Interframe delays for scenario 0: 4510\n",
      "Shape Interframe delays for scenario 0: 4510\n",
      "Shape Interframe delays for scenario 0: 4510\n",
      "Shape Interframe delays for scenario 1: 4500\n",
      "Shape Interframe delays for scenario 1: 4510\n",
      "Shape Interframe delays for scenario 1: 4510\n",
      "Shape Interframe delays for scenario 1: 4510\n",
      "Shape Interframe delays for scenario 2: 4470\n",
      "Shape Interframe delays for scenario 2: 4470\n",
      "Shape Interframe delays for scenario 2: 4470\n",
      "Shape Interframe delays for scenario 2: 4470\n",
      "Shape Interframe delays for scenario 3: 4096\n",
      "Shape Interframe delays for scenario 3: 4096\n",
      "Shape Interframe delays for scenario 3: 4096\n",
      "Shape Interframe delays for scenario 3: 4096\n",
      "Shape Interframe delays for scenario 4: 4500\n",
      "Shape Interframe delays for scenario 4: 4520\n",
      "Shape Interframe delays for scenario 4: 4520\n",
      "Shape Interframe delays for scenario 4: 4520\n",
      "Shape Interframe delays for scenario 5: 4470\n",
      "Shape Interframe delays for scenario 5: 4470\n",
      "Shape Interframe delays for scenario 5: 4470\n",
      "Shape Interframe delays for scenario 5: 4470\n",
      "Shape Interframe delays for scenario 6: 4500\n",
      "Shape Interframe delays for scenario 6: 4520\n",
      "Shape Interframe delays for scenario 6: 4520\n",
      "Shape Interframe delays for scenario 6: 4520\n",
      "Shape Interframe delays for scenario 7: 4500\n",
      "Shape Interframe delays for scenario 7: 4510\n",
      "Shape Interframe delays for scenario 7: 4510\n",
      "Shape Interframe delays for scenario 7: 4510\n",
      "Shape Interframe delays for scenario 8: 4096\n",
      "Shape Interframe delays for scenario 8: 4096\n",
      "Shape Interframe delays for scenario 8: 4096\n",
      "Shape Interframe delays for scenario 8: 4096\n",
      "Shape Interframe delays for scenario 9: 4096\n",
      "Shape Interframe delays for scenario 9: 4096\n",
      "Shape Interframe delays for scenario 9: 4096\n",
      "Shape Interframe delays for scenario 9: 4096\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the data\n",
    "for scenario in range(N_SCN):\n",
    "    for channel in range(N_CHAN):\n",
    "        print(\"Shape Interframe delays for scenario {}: {}\"\n",
    "             .format(scenario, if_time_scn_ch[scenario][channel].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Packet rate for scenario 0: (4510,)\n",
      "Shape variance for scenario 0:    (4510,)\n",
      "Shape Packet rate for scenario 1: (4510,)\n",
      "Shape variance for scenario 1:    (4510,)\n",
      "Shape Packet rate for scenario 2: (4470,)\n",
      "Shape variance for scenario 2:    (4470,)\n",
      "Shape Packet rate for scenario 3: (4096,)\n",
      "Shape variance for scenario 3:    (4096,)\n",
      "Shape Packet rate for scenario 4: (4520,)\n",
      "Shape variance for scenario 4:    (4520,)\n",
      "Shape Packet rate for scenario 5: (4470,)\n",
      "Shape variance for scenario 5:    (4470,)\n",
      "Shape Packet rate for scenario 6: (4520,)\n",
      "Shape variance for scenario 6:    (4520,)\n",
      "Shape Packet rate for scenario 7: (4510,)\n",
      "Shape variance for scenario 7:    (4510,)\n",
      "Shape Packet rate for scenario 8: (4096,)\n",
      "Shape variance for scenario 8:    (4096,)\n",
      "Shape Packet rate for scenario 9: (4096,)\n",
      "Shape variance for scenario 9:    (4096,)\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the packet rate and variance\n",
    "for scenario in range(N_SCN):\n",
    "   print(\"Shape Packet rate for scenario {}: {}\".\n",
    "         format(scenario, packet_rate_scn[scenario].shape))\n",
    "   print(\"Shape variance for scenario {}:    {}\".\n",
    "         format(scenario, variance_scn[scenario].shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cell': {'cm_config': {'lineNumbers': True}},\n",
       " 'CodeCell': {'cm_config': {'autoCloseBrackets': False}},\n",
       " 'load_extensions': {'contrib_nbextensions_help_item/main': True,\n",
       "  'hinterland/hinterland': True,\n",
       "  'nbextensions_configurator/config_menu/main': True,\n",
       "  'ruler/main': True,\n",
       "  'vim_binding/vim_binding': True}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this in Python once, it should take effect permanently\n",
    "from notebook.services.config import ConfigManager\n",
    "c = ConfigManager()\n",
    "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: explain the vector format in markdown - First page of block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a vector that includes the interframe time for all channels\n",
    "if_vector = [[] for i in range(N_SAMPS*N_SCN)]\n",
    "for scn in range(N_SCN):\n",
    "    for i in range(N_SAMPS):\n",
    "        for chan in range(N_CHAN):\n",
    "            if_vector[i + N_SAMPS*scn].append(if_time_scn_ch[scn][chan][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "10\n",
      "40000\n",
      "[ array([-0.35840458, -0.35840458, -0.35840458, ..., -1.        ,\n",
      "       -1.        , -1.        ], dtype=float32)\n",
      " array([-1., -1., -1., ..., -1., -1., -1.], dtype=float32)\n",
      " array([-1.        , -1.        , -1.        , ...,  5.0019269 ,\n",
      "        5.00144863,  5.00144863], dtype=float32)\n",
      " array([ 5.00486422,  5.00344181,  5.00303555, ..., -1.        ,\n",
      "       -1.        , -1.        ], dtype=float32)]\n",
      "[-0.35840458, -1.0, -1.0, 5.0048642]\n"
     ]
    }
   ],
   "source": [
    "print(interframe_delays_scn is if_vector)\n",
    "print(type(interframe_delays_scn))\n",
    "print(type(if_vector))\n",
    "print(len(interframe_delays_scn))\n",
    "print(len(if_vector))\n",
    "print(interframe_delays_scn[0])\n",
    "print(if_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate label vector\n",
    "labels = [i for i in range(N_SCN) for n in range(N_SAMPS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "[(1, 4), (2, 5), (3, 6)]\n",
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "test = list(filter(lambda x: x == 3, labels))\n",
    "print(len(test))\n",
    "l1 = [1, 2, 3] \n",
    "l2 = [4, 5, 6] \n",
    "l3 = list(zip(l1, l2))\n",
    "l4 = l1 + l2\n",
    "print(l3)\n",
    "print(l4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Explain the data list format in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data list that includes all data in a list per frames\n",
    "data = list(if_vector)\n",
    "# first generate a long list that includes the packet_rates one scenario\n",
    "# after the other, and the same for the variances\n",
    "# packet_rate = [scn0, scn1, ..., scn9]\n",
    "# len(packet_rate) = N_SAMPS * N_SCN\n",
    "packet_rate = []\n",
    "variance = []\n",
    "for scn in range(N_SCN):\n",
    "    for i in range(N_SAMPS):\n",
    "            packet_rate.append(packet_rate_scn[scn][i])\n",
    "            variance.append(variance_scn[scn][i])\n",
    "\n",
    "data = list(zip(if_vector, packet_rate, variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2.0014811, 2.0032263, 2.0032263, 2.0014811], 1742.2837, 0.12856445)\n",
      "[2.0014811, 2.0032263, 2.0032263, 2.0014811] 1742.28 0.128564\n",
      "40000 40000\n",
      "3\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "print(data[4000*6+142])\n",
    "print(if_vector[4000*6+142], packet_rate_scn[6][142], variance_scn[6][142])\n",
    "print(len(data), len(labels))\n",
    "print(len(data[0]))\n",
    "what = list(filter(lambda x: len(x) == 3, data))\n",
    "print(len(what))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(len(packet_rate_scn[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'that' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a2dee3e2a845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthaat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthaat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'that' is not defined"
     ]
    }
   ],
   "source": [
    "# START\n",
    "# Try\n",
    "# that = np.array(list(data), dtype=np.float)\n",
    "thaat = np.array(list(labels), dtype=np.float)\n",
    "# np.array(list(X_train), dtype=np.float)\n",
    "print(thaat.shape)\n",
    "print(type(thaat))\n",
    "print(type(that))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    that, thaat, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flattened' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-61fc5cfcbaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0;32m----> 5\u001b[0;31m     flattened, labels, random_state=0)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flattened' is not defined"
     ]
    }
   ],
   "source": [
    "# START\n",
    "# Try\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    flattened, labels, random_state=0)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ff3369eac037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Use pandas to generate a datafram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'interframe delays'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'packet_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'interframe delay variance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m scatter_matrix = pd.plotting.scatter_matrix(learn_dataframe, c=y_train, figsize=(15, 15),\n\u001b[1;32m      6\u001b[0m                                    marker='o')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a scatter matrix from the datagrame, color by y_train\n",
    "# Use pandas to generate a datafram\n",
    "feature_names = ['interframe delays', 'packet_rate', 'interframe delay variance']\n",
    "learn_dataframe = pd.DataFrame(X_train, columns=feature_names)\n",
    "scatter_matrix = pd.plotting.scatter_matrix(learn_dataframe, c=y_train, figsize=(15, 15),\n",
    "                                   marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(learn_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(packet_rate_scn[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving for reference\n",
    "# ---------------------------------------------------------------------------\n",
    "# ValueError                                Traceback (most recent call last)\n",
    "# <ipython-input-104-fa6b7df787e7> in <module>()\n",
    "#       1 from sklearn.neighbors import KNeighborsClassifier\n",
    "#       2 knn = KNeighborsClassifier(n_neighbors=2)\n",
    "# ----> 3 knn.fit(X_train, y_train)\n",
    "# \n",
    "# /home/cuervo/git/learning/python/intro_ml_python/jupyter/env/intro_ml/lib/python3.5/site-packages/sklearn/neighbors/base.py in fit(self, X, y)\n",
    "#     759         \"\"\"\n",
    "#     760         if not isinstance(X, (KDTree, BallTree)):\n",
    "# --> 761             X, y = check_X_y(X, y, \"csr\", multi_output=True)\n",
    "#     762 \n",
    "#     763         if y.ndim == 1 or y.ndim == 2 and y.shape[1] == 1:\n",
    "# \n",
    "# /home/cuervo/git/learning/python/intro_ml_python/jupyter/env/intro_ml/lib/python3.5/site-packages/sklearn/utils/validation.py in check_X_y(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\n",
    "#     519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n",
    "#     520                     ensure_2d, allow_nd, ensure_min_samples,\n",
    "# --> 521                     ensure_min_features, warn_on_dtype, estimator)\n",
    "#     522     if multi_output:\n",
    "#     523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
    "# \n",
    "# /home/cuervo/git/learning/python/intro_ml_python/jupyter/env/intro_ml/lib/python3.5/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\n",
    "#     380                                       force_all_finite)\n",
    "#     381     else:\n",
    "# --> 382         array = np.array(array, dtype=dtype, order=order, copy=copy)\n",
    "#     383 \n",
    "#     384         if ensure_2d:\n",
    "# \n",
    "# ValueError: setting an array element with a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-0.35840458, -1.0, -1.0, 5.0034418], 992.93335, 0.12848413)\n",
      "<class 'list'>\n",
      "[-0.35840458, -1.0, -1.0, 5.0048642]\n"
     ]
    }
   ],
   "source": [
    "# So, apparently (im guessing), scikit learn hates nested lists, and I thought\n",
    "# they were a good idea. So I'm going to flatten the data list but I will \n",
    "# leave the evidence so that I remember for future reference.\n",
    "from itertools import chain\n",
    "\n",
    "print(data[1])\n",
    "print(type(data))\n",
    "flat_data = list(chain.from_iterable(data))\n",
    "print(flat_data[0])\n",
    "# print(type(flat_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35840458, -1.0, -1.0, 5.0048642]\n"
     ]
    }
   ],
   "source": [
    "# Wait! maybe the problem is the zip() function, that returns tuples. Checking\n",
    "# that first here:\n",
    "\n",
    "# UPDATE: NOPE! wasn't it. Now flattening\n",
    "print(if_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35840458, -1.0, -1.0, 5.0048642]\n",
      "[[-0.35840458, -1.0, -1.0, 5.0048642], 2122.9348, 0.12846743]\n",
      "([-0.35840458, -1.0, -1.0, 5.0048642], 2122.9348, 0.12846743)\n",
      "[-0.35840458, -1.0, -1.0, 5.0048642]\n"
     ]
    }
   ],
   "source": [
    "# Generate data list that includes all data in a list per frames\n",
    "# data_flat = list(if_vector)\n",
    "# first generate a long list that includes the packet_rates one scenario\n",
    "# after the other, and the same for the variances\n",
    "# packet_rate = [scn0, scn1, ..., scn9]\n",
    "# len(packet_rate) = N_SAMPS * N_SCN\n",
    "packet_rate = []\n",
    "variance = []\n",
    "for scn in range(N_SCN):\n",
    "    for i in range(N_SAMPS):\n",
    "            packet_rate.append(packet_rate_scn[scn][i])\n",
    "            variance.append(variance_scn[scn][i])\n",
    "data_flat = [list(a) for a in zip(if_vector, packet_rate, variance)]\n",
    "# BEFORE flatening ^^^\n",
    "# Flatenning:\n",
    "\n",
    "# flat_data = list(chain.from_iterable(data_flat)) # <- This aint doing shit\n",
    "flat_data = list(chain.from_iterable(data_flat)) # <- This aint doing shit\n",
    "print(if_vector[0])\n",
    "print(data_flat[0])\n",
    "print(data[0])\n",
    "print(flat_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35840458, -1.0, -1.0, 5.0048642], 2122.9348, 0.12846743]\n",
      "([-0.35840458, -1.0, -1.0, 5.0048642], 2122.9348, 0.12846743)\n",
      "2122.93\n",
      "[-0.35840458, -1.0, -1.0, 5.0048642, 2122.9348, 0.12846743]\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "print(data_flat[0])\n",
    "print(data[0])\n",
    "print(flat_data[1])\n",
    "flattened = [[] for i in range(len(data))]\n",
    "for i in range(len(data)):\n",
    "    flattened[i] = list(flatten(data[i]))\n",
    "print(flattened[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0017843, 5.0017843, -1.0, -1.0, 372.16083, 0.12860508]\n"
     ]
    }
   ],
   "source": [
    "# START\n",
    "# Try\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    flattened, labels, random_state=0)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-56-dc68fec63b34>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-dc68fec63b34>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    tree.fit(\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing training in a loop\n",
    "knn_list = []\n",
    "predictions = []\n",
    "accs = []\n",
    "n_neighbors = [2, 4, 10, 50]\n",
    "for n in range(len(n_neighbors)):\n",
    "    knn_list.append(KNeighborsClassifier(n_neighbors=n_neighbors[n]))\n",
    "    knn_list[n].fit(X_train, y_train)\n",
    "    predictions.append(knn_list[n].predict(X_test))\n",
    "    accs.append(accuracy_score(y_test, predictions[n]))\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99819999999999998, 0.99819999999999998, 0.99809999999999999, 0.99660000000000004]\n"
     ]
    }
   ],
   "source": [
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "100\n",
      "1000\n",
      "10000\n",
      "100000\n",
      "[0.99050000000000005, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003]\n"
     ]
    }
   ],
   "source": [
    "# Training in a loop using SVM\n",
    "# http://scikit-learn.org/stable/modules/svm.html\n",
    "from sklearn.svm import SVC\n",
    "svc_list = []\n",
    "svc_pred = []\n",
    "svc_accs = []\n",
    "svc_complexities = [1, 10, 100, 1000, 10000, 100000]\n",
    "\n",
    "for n in range(len(svc_complexities)):\n",
    "    print(svc_complexities[n])\n",
    "    svc_list.append(SVC(kernel='rbf', C=float(svc_complexities[n])))\n",
    "    svc_list[n].fit(X_train, y_train)\n",
    "    svc_pred.append(svc_list[n].predict(X_test))\n",
    "    svc_accs.append(accuracy_score(y_test, svc_pred[n]))\n",
    "    \n",
    "print(svc_accs)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "rfc_list = []\n",
    "rfc_pred = []\n",
    "rfc_accs = []\n",
    "rfc_estimators = [1, 10, 100, 1000, 10000, 100000]\n",
    "rfc_jobs = [1, 2, 3]\n",
    "rfc_fit_times = [[] for i in range(len(rfc_jobs))]\n",
    "rfc_pred_times = [[] for i in range(len(rfc_jobs))]\n",
    "\n",
    "for job in range(len(rfc_jobs)):\n",
    "    for n in range(len(rfc_estimators)):\n",
    "        rfc_list.append(RandomForestClassifier(n_estimators=rfc_estimators[n],\n",
    "                                              n_jobs=rfc_jobs[job]))\n",
    "        t0 = time()\n",
    "        rfc_list[n].fit(X_train, y_train)\n",
    "        rfc_fit_times[job].append(round(time() - t0, 3))\n",
    "        t0 = time()\n",
    "        rfc_pred.append(svc_list[n].predict(X_test))\n",
    "        rfc_pred_times[job].append(round(time() - t0, 3))\n",
    "        rfc_accs.append(accuracy_score(y_test, svc_pred[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99050000000000005, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99050000000000005, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99050000000000005, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003, 0.99170000000000003] \n",
      " [[0.053, 0.177, 1.426, 13.83, 143.471, 1384.964], [0.047, 0.169, 1.419, 13.664, 136.452, 1409.797], [0.047, 0.165, 1.389, 13.685, 137.151, 1407.944]] \n",
      " [[1.479, 1.444, 1.475, 1.457, 1.534, 1.439], [1.484, 1.449, 1.446, 1.451, 1.436, 1.448], [1.468, 1.445, 1.444, 1.444, 1.446, 1.453]]\n"
     ]
    }
   ],
   "source": [
    "print(rfc_accs, '\\n', rfc_fit_times, '\\n', rfc_pred_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn impor"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
